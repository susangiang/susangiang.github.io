<html>
  <head>
    <link rel="stylesheet" type="text/css" href="styles/index.css">
    <title>Designing Scheduling Experiments - Case Study</title>
    <meta name="viewport" content="width=device-width; initial-scale=1.0" />
    <meta name="description" content="Opencare case study by Susan Giang.">
    <link rel="canonical" href="http://www.susangiang.ca/opencare" />
    <link rel="shortcut icon" href="../images/assets/favicon.ico" type="image/x-icon">
  </head>

  <body>
    <div class="project-content">
      <div class="container">
        <div class="navigation-container">
          <a href="/" class="navigation__item">Back to Home</a>
        </div>

        <div class="section">
          <h1 class="project-name">Designing scheduling experiments</h1>
          <p class="project__page--description">Opencare</p>
          <h2 class="project__subhead">Context</h2>
          <div class="project-body">
            <p>
              Founded in 2012, Opencare is a healthcare startup with a mission to make healthcare more personable, approachable, and accessible. Patients are connected with dentalcare providers and the interactions that take place in between are redefined through a streamlined booking platform.
            </p>

            <p>
              Opencare's Instant Book feature integrates with dental practices' management software to automatically populate available timeslots on the Opencare platform that patients can request for. With practices stretched thin, Instant Book takes away the effort needed to manually provide availabilities to Opencare. For patients, there is more visibility into practice availability upfront, allowing them to arrange their next dental visit efficiently.
            </p>
          </div>

          <h2 class="project__subhead">Role</h2>
          <div class="project-body">
            <p>
              I was the sole designer on the Growth team, focused on understanding the barriers to entry and running rapid experiments to drive higher revenue and key metrics. Over the course of 2 weeks, I worked closely alongside the growth product manager to develop a deep understanding of patient and practice pains through user interviews and data analysis. I also communicated with the engineers throughout the duration of the project; from identifying constraints and technical limitations to ensuring accurate implementation of the final designs after handoff.
            </p>
          </div>

          <h2 class="project__subhead gutter-bottom" style="margin-bottom: 20px;">Process</h2>
          <h3 class="project__subcontent">Data</h3>
          <div class="project-body">
            <p>
              From the data we learned that that it takes an average of 4-5 days for a practice to successfully book a patient in for a visit. This is due to the back and forth interactions that take place between patients and practices during the scheduling process. We noticed that that the more back and forth there was, the less likely the appointment would be scheduled, resulting in a cancelled patient request.
            </p>
            <p>
              We compared Instant Book adoption rates of our Canadian and American practices and saw that in general, Canadian practices on the platform take longer to schedule patients in because the adoption rate is half of that of American practices. With more than half of Canadian practices on Opencare not using the feature, this meant that more communication was needed with patients in order to get booked successfully. We decided to focus on the Canadian market as it had the lower schedule rate and Instant Book adoption rate.
            </p>
          </div>

          <h3 class="project__subcontent">Qualitative Research</h3>
          <div class="project-body">
            <p>
              I interviewed 5 patients remotely and 1 practice in person to better understand our endusers’ experiences with scheduling through Opencare and synthesized the findings.            </p>
            </p>
            <figure style="text-align: center; margin: 0;">
              <img style="max-width: 100%; margin-bottom: 30px; margin-top: 30px" src="/images/assets/opencare/trello.jpg">
              <figcaption>
                Synthesis notes using Trello
              </figcaption>
            </figure>
            <p>
              Upon diving deeper and conducting user interviews, we were able to pin the cause of the back and forth communications to two main reasons:
              <ol style="list-style-type: : none; padding-left: 20px;">
                <li>
                  Instabook failure
                  <p>
                    For the practices that use Instant Book, their dental practice management softwares are dated and pose many technical limitations when it comes to integration. As a result, Instant Book accuracy is low and many open appointments that were requested by patients were not actually available anymore, creating frustration and additional effort on both parties' part to find a new time that works for everyone.
                  </p>
                </li>

                <li>
                  Non-IB Practices
                  <p>
                    The majority of Canadian practices don't use Instant Book. This naturally meant that practices would need to have additional touchpoints with patients in order to find a suitable time.
                  </p>
                </li>
              </ol>
            </p>
          </div>

          <h3 class="project__subcontent">Hypotheses</h3>
          <div class="project-body">
            <p>
              The insights that we had drawn from analytics and qualitative research validated our assumption that lack of understanding of each other's schedules and preferences required patients and practices to engage in more back/forth communications. Next, I worked with my product manager to generate a list of hypotheses that we could test – we decided to focus on the patient-facing side of Opencare, knowing that practices are often working at full capacity and don’t have the extra time to update their availabilites on the platform. Evaluating our hypotheses using a prioritization framework that looked at impact, confidence, and ease, we landed on the following hypothesis:
            </p>
            <p style="font-weight: bold;">
              By allowing patients to provide more information on their time preferences upfront, practices will be able to provide available times that are more relevant and suitable for the patient, ultimately reducing the back and forth needed to successfully schedule a patient in.
            </p>
          </div>

          <h3 class="project__subcontent">Measuring Success</h3>
          <div class="project-body">
            <p>
              Our goal was to ultimately reduce the back and forth between patients and practices; this meant providing practices with more insights on what times work best for patients. Primary and secondary metrics that would deem this experiment a success were:
            </p>
            <h4>Primary</h4>
            <ol style="list-style-type: : none; padding-left: 20px;">
              <li>ncrease in number of scheduled appointments after a request has been submitted (schedule rate)</li>
            </ol>
            <h4>Secondary</h4>
            <ol style="list-style-type: : none; padding-left: 20px;">
              <li>Reduced number of back/forth interactions between patients and practices</li>
              <li>Reduced time taken to successfully schedule a patient in</li>
            </ol>
          </div>

          <h3 class="project__subcontent">Design</h3>
          <div class="project-body">
            <h4>Current State</h4>
            <p>
              There are currently two different points in the user flow in which we prompt patients to provide more information on their availailities: within the initial questionnaire (an optional question where patients can specify their preferred time(s) of day) and during the flow to request an appointment with a specific practice (presented as an optional open text field). With these prompts being optional, we noticed many patients selecting “No preferences” and simply not filling out the optional text field.
            </p>

            <figure style="text-align: center; margin: 0;">
              <img style="max-width: 100%; margin-bottom: 30px; margin-top: 30px" src="/images/assets/opencare/opencare_2.png">
              <figcaption>
                Current state: Questionnaire (left) and within appointment request flow (right)
              </figcaption>
            </figure>

            <p>
              I opted to experiment with the latter because I hypothesized that since patients are much further down the funnel, their intent to book is higher and they would be more likely to provide additional information on their availabilities. Making this step required would allow us to collect more quality and consistent data on patient preferences.
            </p>
            <p>
              After bouncing some initial ideas with my product product manager and engineers, I created hi-fidelity mockups of the design solutions that were most promising. For each option, we considered the impact and level of effort required, focusing on creating an MVP that would validate or disprove our hypothesis.
            </p>

            <h4>Option #1: Dropdowns</h4>
            <figure style="text-align: center; margin: 0;">
              <img style="max-width: 100%; margin-bottom: 30px; margin-top: 30px" src="/images/assets/opencare/opencare_3.png">
            </figure>
            <p>
              The first option looked to reuse existing components, knowing that we were looking for a solution that was easy to implement in a short amount of time. This option uses two dropdowns that allows the patient to select preferred day(s) and within those days, what time(s) they preferred.
            </p>
            <h5>Pros</h5>
            <ul>
              <li>Ability to provide more granular preferences, such as specific time ranges for certain days of the week</li>
              <li>Space concious; horizontally stacking the dropdowns meant that vertical real estate is not jeopardized</li>
            </ul>

            <h5>Cons</h5>
            <ul>
              <li>Looks clunky in instance of multiple rows</li>
              <li>Probability of error is high (patient may select conflicting time ranges for the same day)</li>
              <li>Inability to see what’s been selected at a glance with the collapsed dropdowns</li>
            </ul>

            <h4>Exploration #2: Split view </h4>
            <figure style="text-align: center; margin: 0;">
              <img style="max-width: 100%; margin-bottom: 30px; margin-top: 30px" src="/images/assets/opencare/opencare_4.png">
            </figure>
            <p>
              The second option looked at splitting the current state into multiple screens in attempt to reduce cognitive load and allow patients to focus on the task at hand. The initial screen would ask patients to specifiy preferred days of the week, of which the selected day(s) will be carried over to the next screen where they will specifiy what time(s) of day work best for each selection.             </p>
            </p>
            <h5>Pros</h5>
            <ul>
              <li>Clearer presentation, making the content more digestable</li>
              <li>Additional real estate lends itself well for the expandable accordions</li>
              <li>Easy to what’s been selected at a glance</li>
            </ul>

            <h5>Cons</h5>
            <ul>
              <li>Adds additional steps to the request flow, which may deter patients away from moving forward</li>
              <li>Patient is unable to apply the time(s) of day preferences across multiple days; they must repeat the same selections for each day they selected in the previous screen</li>
            </ul>

            <h4>Option #3: Availability Matrix</h4>
            <figure style="text-align: center; margin: 0;">
              <img style="max-width: 100%; margin-bottom: 30px; margin-top: 30px" src="/images/assets/opencare/opencare_5.png">
            </figure>
            <p>
              The last option is the most complex of them all but also the most efficient. Upon selecting the preferred day(s), a table displays with the respective day(s) as the column titles and time of day as row titles. Patients would be able to select the checkboxes as needed, along with the ability to apply a specific time of day across multiple days.
            </p>
            <h5>Pros</h5>
            <ul>
              <li>Ability to apply the time(s) of day preferences across multiple days</li>
            </ul>

            <h5>Cons</h5>
            <ul>
              <li>Visually overwhelming with all of the checkboxes</li>
              <li>Not the most mobile-friendly / error-prone</li>
              <li>Requires more development effort than necessary for a small-scaled experiment</li>
            </ul>
          </div>

          <h3 class="project__subcontent">Final Design</h3>
          <div class="project-body">
            <p>
              While we felt that Option 2 or Option 3 would be the most interesting experiments to run, we were ultimately constrained by the time left within the sprint and the engineering team being at capacity. We took a step back to think critically about what the minimal viable test is and what is the most simplified design solution that will get us the learnings we need to validate our hypothesis. In the end, we aimed to put out an experiment that simply made it mandatory for patients to enter their time preferences (day(s) of week and time(s) of day). While this meant that we wouldn’t be able to get as granular as we wanted, we would still be able to test whether this new additional information woul help practices and increase the schedule rate.
            </p>
            <figure style="text-align: center; margin: 0;">
              <img style="max-width: 100%; margin-bottom: 30px; margin-top: 30px" src="images/assets/opencare/opencare_6.png">
            </figure>
            <p>
              In the final design, the preferred time(s) of day is pre-populated based on what the patient selected in the questionnaire. They are then prompted to select the day(s) of the week that work best for them. We also removed the “No preference” option so that responses would be as specific as possible.
            </p>
          </div>

          <h3 class="project__subcontent">Results</h3>
          <div class="project-body">
            <p>
              After running the experiment and looking back at our success metrics, we assessed whether we were successful.
            </p>

            <h4>Primary</h4>
            <ol style="list-style-type: : none; padding-left: 20px;">
              <li>Increase in number of scheduled appointments after a request has been submitted (schedule rate)<br> Result: No change</li>
            </ol>

            <h4>Secondary</h4>
            <ol style="list-style-type: : none; padding-left: 20px;">
              <li>Reduced number of back/forth interactions between patients and practices <br> Result: No change</li>
              <li>Reduced time taken to successfully schedule a patient in <br> Result: No change </li>
            </ol>

            <p>
              Based on the data, we dispoved the hypothesis and marked this experiment a fail (but that’s the fun of experimentation). However, we noticed that the number of patient requests did not decrease, an indicator that the new addition to the request flow did not cause patients to drop off. This meant that we would be able to gather more information on patient availability without sacrificing new requests – a win! A small win that came out of this experiment was that we actually decided to roll this addition to the platform permanently.
            </p>
          </div>

          <h3 class="project__subcontent">Learnings & Reflection</h3>
          <div class="project-body">
            <p>
              From this short project, I learned a lot about hypothesis-based design and had the chance to dive deep into data. Opencare is extremely data-driven and it was handy to have easy access into the numbers, which helped us form a narrative around the issues we needed to solve. Although this experiment wasn’t a success, there were several key learnings that came out of this 2-week stint.
            </p>

            <h4>Failed experiments are just as good as successful ones, if not better.</h4>
            <p>Like a usability test, the more criticism and negative feedback you get, the better your understanding of your users and how they work. By failing, we learned more about our patients and practices’ behaviours that would inform future experiments, allowing us to answer some of the why’s along the way. </p>

            <h4>Focus on the learnings.</h4>
            <p>
              As someone whose previous role was very much fixated on pixel-perfect, production design, I learned to let go of being the perfectionist. Working quickly and getting experiments ready for testing (even if they weren’t the most polished designs) was a valuable skill to have as a designer on the Growth team. Most experiments don’t stick, so getting it out there was key in order to obtain learnings as fast as we could.
            </p>

            <h4>You need to be bold to push the needle.</h4>
            <p>
              As shown by this project, the experiment we ran introduced minor tweaks to the current state and yielded subpar results. It’s not often enough to make these types of small changes to create a significant dent in key metrics. Sometimes it’s a matter of taking the leap of faith with bolder ideas, where the outcomes can be just as unexpected.
            </p>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
